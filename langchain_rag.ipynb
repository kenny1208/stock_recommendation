{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import nltk\n",
    "from langchain_text_splitters import NLTKTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from IPython.display import Markdown as md\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  \n",
    "key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1'}, page_content='類神經網路基礎\\n王豐緒\\n銘傳大學資工系'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2'}, page_content='學習目標\\n• 理解類神經元的基本結構與運作方式\\n• 理解何謂Perceptron類神經網路\\n• 理解類神經的學習方式\\n• 理解類神經的訓練與測試過程\\n• 理解矩陣運算與類神經的關聯\\n2'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3'}, page_content='大綱\\n• 類神經元的結構與運作\\n• Perceptron類神經網路\\n• 學習方程式\\n• 學習速率的選擇\\n• 訓練與測試\\n• 訓練階段(backward process)\\n• 測試階段(Forward Process)\\n• 矩陣運算與類神經\\n• 小結\\n3'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4'}, page_content='大腦神經元(NEURONS)\\n• 神經元\\n• 大腦中的處理單元（1000億個，1011）\\n• 每個通過突觸與其他神經元相連（1千兆\\n個，1014）\\n• 具有可塑性和堅韌的操作性\\n• 經由學習，修改突觸強度\\n• 經由學習，建立新連接 (突觸，Synapse)\\n4\\n(source: Wiki)\\nneuron\\n決定是否觸發\\n突觸'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 4, 'page_label': '5'}, page_content='類神經元(ARTIFICIAL NEURONS)\\n• McCulloch and Pitts Neurons\\n5\\nh\\nx1\\nx2\\nxm\\nw1\\nw2\\nwm\\nO\\n…\\n-1\\n𝜃\\n偏值(bias)\\nneuron\\n在所有输入都是零的情况下需要\\n𝑜 = 𝑔(ℎ) = ቊ1 𝑖𝑓 ℎ > 0\\n0 𝑖𝑓 ℎ ≤ 0\\nℎ = \\u0dcd\\n𝑖\\n𝑊𝑖𝑋𝑖 − 𝜃\\n𝑔 : 激活函數 (activation function)\\nX: the input vector: [x1, x2, …, xm, -1]\\nW: the weight vector: [w1, w2, …, wm, 𝜃]\\n𝑜 = 𝑔(𝑊 ⊙ 𝑋)\\n⊙ : the inner product of 𝑊，𝑋'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 5, 'page_label': '6'}, page_content='PERCEPTRON類神經網路\\n• 最早的多神經元網路\\n• 啟發式學習法則\\n6\\n𝑥𝑖: 網路輸入\\n𝑦𝑗: 網路輸出\\n𝑡𝑗 : 真正的輸出\\n𝜂 : 學習速率 (learning rate)\\n𝑥𝑖 𝑦𝑗\\n△ 𝑤𝑖𝑗= −𝜂(𝑦𝑗 − 𝑡𝑗) ∙ 𝑥𝑖 WHY?\\n學習方程式\\n𝑦𝑗 − 𝑡𝑗\\n高估(𝑦𝑗 > 𝑡𝑗)\\n低估(𝑦𝑗 < 𝑡𝑗)\\n降低訊號強度z\\n增強訊號強度z\\n𝑧 = 𝑥𝑖𝑤𝑖𝑗目標\\n-\\n+\\n𝑥𝑖 𝑛𝑗\\n𝑤𝑖𝑗\\n𝑦𝑗\\n𝑧 = 𝑥𝑖𝑤𝑖𝑗'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7'}, page_content='學習速率的選擇\\n• 較小的 learning rate\\n• 學習較慢\\n• 較能容忍資料雜訊和資料不一致性\\n• 較大的 learning rate\\n• 較不穩定\\n• 實務上\\n• 可嘗試 0.1 < 𝜂 <0.4\\n7\\n△ 𝑤𝑖𝑗= −𝜂(𝑦𝑗 − 𝑡𝑗) ∙ 𝑥𝑖'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8'}, page_content=\"訓練(TRAIN)與測試(TEST)\\n• 訓練階段\\n• 將訓練數據x輸入到類神經網路中\\n並更新權重直到輸出正確答案y\\n• 測試階段\\n• 將測試數據x輸入到類神經網路中\\n並取得網路輸出y'\\n8\\n類神經網路\\n(W)x y\\n類神經網路\\n(W)x y'\"),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9'}, page_content='訓練階段(BACKWARD PROCESS)\\n• 輸入訓練資料 : 𝐷(𝑀+1)×𝑁\\n• N筆 (M+1)-input 向量\\n• 加入偏值向量(-1)\\n• 輸出訓練資料 : 𝐿𝑂×𝑁\\n• 權重向量(Weight Matrix)\\n• 𝑊(𝑀+1)×𝑂\\n• 加入偏值權重(B)(bias weight): 𝐵1×𝑂\\n• 網路輸出Y : 𝑌𝑂×𝑁\\n• 總權重修正量矩陣: ∆𝑊𝑂×(𝑀+1)\\n9\\n𝑊𝑂×(𝑀+1)\\n𝑇 × 𝐷(𝑀+1)×𝑁= 𝐻𝑂×𝑁\\n𝑌𝑂×𝑁= 𝑔(𝐻𝑂×𝑁)\\n∆𝑊=−𝜂𝐷(𝑀+1)×𝑁 × (𝑌𝑂×𝑁 − 𝐿𝑂×𝑁)𝑇\\nB   \\nWM\\nO\\n1\\n-1\\nD\\nN\\nM LO\\nN\\n1\\nYO\\nN\\n𝑥𝑖 𝑦𝑗'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10'}, page_content='訓練階段(BACKWARD PROCESS)\\n10\\n−1\\nbias\\nD O\\nB   \\nWM\\nO\\n1\\nY O\\nN\\n-11\\nD\\nN\\nM\\nN\\nLO\\n△ 𝒘𝒊𝒋= −𝜼(𝒚𝒋 − 𝒕𝒋) ∙ 𝒙𝒊'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11'}, page_content='訓練階段(BACKWARD PROCESS)\\n11\\nx1\\nx2\\n-1\\ny1\\ny2\\n0.4\\n0.8\\n0.1\\n0.3\\n0.5\\n0.2\\nD=\\n0 1 1\\n1 0 1\\n−1 −1 −1\\nL= 1 0 1\\n1 0 0 W=\\n0.4 0.8\\n0.1 0.3\\n0.5 0.2\\n𝐻 = 𝑊𝑇 × 𝐷 = 0.4 0.1 0.5\\n0.8 0.3 0.2 ×\\n0 1 1\\n1 0 1\\n−1 −1 −1\\n= −0.4 −0.1 0\\n0.1 0.6 0.9\\n𝑌= 𝑔 𝐻 = 0 0 0\\n1 1 1\\n∆𝑊=−𝜂𝐷 𝑀+1 ×𝑁 × 𝑌𝑂×𝑁 − 𝐿𝑂×𝑁 𝑇\\n= −0.1 ∙\\n0 1 1\\n1 0 1\\n−1 −1 −1\\n×\\n−1 0\\n0 1\\n−1 1\\n= −0.1 ∙\\n−1 2\\n−2 1\\n2 −2\\n=\\n0.1 −0.2\\n0.2 −0.1\\n−0.2 0.2\\n1 1 0\\n1 0 1\\n0 0 0\\n1 1 1'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12'}, page_content='感知器的更新訓練演算法\\n12\\nStart\\nData size = N\\nMini-batch size = m\\nepochs: e\\nGenerate \\n𝑁\\n𝑚 random batches  of \\nsamples\\nNO\\nTrain with next batch\\nFinished \\nall\\nbatches?\\nNO\\nYES\\nYES\\nEnd\\nFinished \\ne\\nepochs?\\n(one epoch)'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13'}, page_content='測試階段(FORWARD PROCESS)\\n13\\n−1\\nbias\\nO\\nB   \\nWM\\nO\\n1\\nY O\\nN\\n-11\\nD\\nN\\nM\\n給定一組包含 N 個 M 輸入向量的輸入數據（D）和標籤數據（L），權重矩陣（W），\\n計算網絡的輸出數據（Y）\\nN\\nL O\\nD\\nW\\nB'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14'}, page_content='測試階段(FORWARD PROCESS)\\n• 輸入測試資料 : 𝐷(𝑀+1)×𝑁\\n• N筆 (M+1)-input 向量\\n• 加入偏值向量(-1)\\n• 輸出測試資料 : 𝐿𝑂×𝑁\\n• 權重向量(Weight Matrix)\\n• 𝑊(𝑀+1)×𝑂\\n• 加入偏值權重(B)(bias weight): 𝐵1×𝑂\\n• 網路輸出Y : 𝑌𝑂×𝑁\\n• 方差矩陣(Total Squared Error Matrix): 𝐸𝑁\\n14\\n𝑊𝑂×(𝑀+1)\\n𝑇 × 𝐷(𝑀+1)×𝑁= 𝑍𝑂×𝑁\\n𝑌𝑂×𝑁= 𝑔(𝑍𝑂×𝑁)\\n𝐸𝑁= 𝑆𝑈𝑀𝑐𝑜𝑙\\n2 (𝑌𝑂×𝑁 − 𝐿𝑂×𝑁)\\nB   \\nWM\\nO\\n1\\n-1\\nD\\nN\\nM LO\\nN\\n1\\nYO\\nN\\ng Y'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15'}, page_content='測試階段(FORWARD PROCESS)\\n15\\n𝑍 = 𝑊𝑇 × 𝐷 = 5 8 7\\n6 9 10 ×\\n1 3\\n2 4\\n−1 −1\\n= 14 32\\n14 44\\n𝑌= 𝑔 𝑍 = 1 1\\n1 1\\n𝐸𝑁= 𝑆𝑈𝑀𝑐𝑜𝑙\\n2 𝑌 − 𝐿 = 𝑆𝑈𝑀𝑐𝑜𝑙\\n2 1 1\\n1 1 − 1 3\\n2 4 = 𝑆𝑈𝑀𝑐𝑜𝑙\\n2 0 −2\\n−1 −3 = [1 13]\\n-1\\n1\\n2\\n3\\n4\\n7\\n5\\n6\\n8\\n9\\n10\\n𝐷 =\\n1 3\\n2 4\\n−1 −1\\n𝑊 =\\n5 6\\n8 9\\n7 10\\n1\\n1\\n1\\n1\\n𝐿 = 1 3\\n2 4'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16'}, page_content='測試階段(FORWARD PROCESS)\\n16\\nx1\\nx2\\n-1\\ny1\\ny2\\n0.4\\n0.8\\n0.1\\n0.3\\n0.5\\n0.2\\nD=\\n0 1 1\\n1 0 1\\n−1 −1 −1\\nL= 1 0 1\\n1 0 0 W=\\n0.4 0.8\\n0.1 0.3\\n0.5 0.2\\n𝑍 = 𝑊𝑇 × 𝐷 = 0.4 0.1 0.5\\n0.8 0.3 0.2 ×\\n0 1 1\\n1 0 1\\n−1 −1 −1\\n= −0.4 −0.1 0\\n0.1 0.6 0.9\\n𝑌= 𝑔 𝐻 = 0 0 0\\n1 1 1\\n𝐸 = 𝑆𝑈𝑀𝑐𝑜𝑙\\n2 ( 0 0 0\\n1 1 1 − 1 0 1\\n1 0 0 )=𝑆𝑈𝑀𝑐𝑜𝑙\\n2 −1 0 −1\\n0 1 1 = [1 1 2]'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17'}, page_content='矩陣運算與類神經\\n• 為什麼要以矩陣視角看待神經網路操作？\\n• 延伸至對 TensorFlow 的觀點（何謂張量(Tensor)？）\\n• 對於在晶片上（例如 GPU）進行高速計算很有用\\n• 在訓練階段，權重更新矩陣是由所有 N 筆訓練數據與原始網路權重計算收集而來\\n• 如果 N 很大會發生什麼？\\n• 如果選擇每個單一訓練數據來更新權重呢？\\n17\\nSee how matrix multiplication can be reduced to O(N) from O(N3) with parallel computation \\n(https://www.sciencedirect.com/science/article/pii/0167819189900574)'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18'}, page_content='小結\\n• 單一神經元的模型（McCulloch和Pitts 神經元）\\n• 神經元的運作方式\\n• 感知器\\n• 如何透過導出學習規則來訓練神經網路\\n• 測試感知器，看神經網絡如何進行訓練和操作\\n• 初始化權重\\n• 訓練\\n• 測試\\n• 學習將神經網路操作視為矩陣操作\\n• 學習典型的訓練過程\\n• 小批次大小\\n• 執行周期的次數\\n18'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19'}, page_content='參考文獻\\n• [1] Machine Learning: An Algorithmic Perspective, by Stephen Marsland, \\npublished by CRC Press (2014).\\n19'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20'}, page_content='Q&A\\n20')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model = ChatGoogleGenerativeAI(google_api_key=key, \n",
    "                                   model=\"gemini-1.5-pro-latest\")\n",
    "loader = PyPDFLoader(\"../data/1neural_network.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "text_splitter = NLTKTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "print(len(chunks))\n",
    "print(type(chunks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36873/164989724.py:3: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n",
      "/tmp/ipykernel_36873/164989724.py:4: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db_connection = Chroma(persist_directory=\"../chroma_db_\", embedding_function=embedding_model)\n"
     ]
    }
   ],
   "source": [
    "embedding_model = GoogleGenerativeAIEmbeddings(google_api_key=key, model=\"models/embedding-001\")\n",
    "db = Chroma.from_documents(chunks, embedding_model, persist_directory=\"../chroma_db_\")\n",
    "db.persist()\n",
    "db_connection = Chroma(persist_directory=\"../chroma_db_\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.vectorstores.base.VectorStoreRetriever'>\n"
     ]
    }
   ],
   "source": [
    "retriever = db_connection.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "print(type(retriever))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"\"\"You are a teacher in Scaffolding Instruction education.\n",
    "                  Given a context and question from user,\n",
    "                  you should answer based on the given context.\"\"\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"\"\"Answer the question based on the given context.\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    Answer: \"\"\")\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | chat_template\n",
    "    | chat_model\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the context provided, a neural network, inspired by biological neurons in the brain, is a computing system composed of interconnected processing units called neurons (or perceptrons in the context of a Perceptron neural network, an early type of multi-neuron network).  These artificial neurons receive weighted inputs, sum them, and apply an activation function to produce an output.  Learning occurs by adjusting the connection weights between neurons based on the difference between the network's output and the desired output (using a learning rate). This process, aimed at strengthening or weakening signal intensity, allows the network to improve its performance over time through training and testing phases.  Matrix operations are involved in the calculations within the network."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"\"\"Please summarize what is a neural network\"\"\")\n",
    "md(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "提供的文本沒有詳細解釋權重（weights）本身的含義和作用，只在公式中展示了權重符號 *Wᵢ* 以及它如何與輸入 *Xᵢ*  一起使用。\n",
       "\n",
       "要詳細解釋權重，需要補充以下信息：\n",
       "\n",
       "* **權重代表輸入的重要性：**  每個輸入 *Xᵢ* 都有一個对应的權重 *Wᵢ*.  權重值越大，表示該輸入對神經元最終輸出的影響越大。反之，權重值越小，則表示該輸入對輸出的影響越小。\n",
       "\n",
       "* **權重如何影響輸出：** 神經元將所有輸入乘以它們各自的權重，然後將這些乘積加總起來。  這個加總的結果，再加上一個偏置值 (bias)，將決定神經元的激活狀態。\n",
       "\n",
       "* **權重是學習的關鍵：**  在訓練神經網絡的過程中，不斷調整權重值，以使網絡的輸出更接近預期的結果。  學習的過程本質上就是找到一組最佳的權重值。\n",
       "\n",
       "* **權重與突觸的類比：**  可以將權重比作生物神經元之間突觸的強度。  突觸強度越大，信號傳遞就越有效。  權重在人工神經網絡中扮演着类似的角色。\n",
       "\n",
       "* **權重初始化：**  在開始訓練之前，需要對權重進行初始化。  初始化方法有很多，例如随机初始化、使用特定分布初始化等。  初始化值的选择会影响训练的效果。\n",
       "\n",
       "\n",
       "總而言之，權重是神經網絡的核心組成部分，它們決定了網絡如何處理輸入並產生輸出。  通過調整權重，神經網絡可以學習複雜的模式和關係。  提供的文本提到了權重，但缺乏對其更深入的解釋。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"\"\"詳細解釋權重\"\"\")\n",
    "\n",
    "md(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
